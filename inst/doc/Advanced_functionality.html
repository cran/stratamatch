<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Advanced Functionality</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Advanced Functionality</h1>



<p><strong>Summary:</strong> “Introduction to stratamatch” covers the basic functionality of <code>stratamatch</code>: stratifying a data set, assessing the quality of the match, and matching the data within strata. This vignette features more advanced functionality of <code>stratamatch</code>.</p>
<p>This vignette contains:</p>
<ol style="list-style-type: decimal">
<li>Set-up</li>
<li>Splitting the pilot set</li>
<li>Fitting the prognostic model</li>
<li>Alternative matching schemes</li>
</ol>
<div id="set-up" class="section level1">
<h1>Set up</h1>
<p>We’ll start with some sample data:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(stratamatch)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">library</span>(dplyr)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="co">#&gt; Attaching package: 'dplyr'</span></a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="co">#&gt; The following objects are masked from 'package:stats':</span></a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb1-7" data-line-number="7"><span class="co">#&gt;     filter, lag</span></a>
<a class="sourceLine" id="cb1-8" data-line-number="8"><span class="co">#&gt; The following objects are masked from 'package:base':</span></a>
<a class="sourceLine" id="cb1-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb1-10" data-line-number="10"><span class="co">#&gt;     intersect, setdiff, setequal, union</span></a>
<a class="sourceLine" id="cb1-11" data-line-number="11"><span class="kw">set.seed</span>(<span class="dv">123</span>)</a>
<a class="sourceLine" id="cb1-12" data-line-number="12">mydata &lt;-<span class="st"> </span><span class="kw">make_sample_data</span>(<span class="dt">n =</span> <span class="dv">5000</span>)</a></code></pre></div>
</div>
<div id="splitting-the-pilot-set" class="section level1">
<h1>Splitting the pilot set</h1>
<p>An important consideration for pilot designs like the <code>stratamatch</code> approach is the selection of the pilot set. Ideally, the individuals in the pilot set should be similarto the individuals in the treatment group, so a prognostic model built on this pilot set will not beextrapolating heavily when estimating prognostic scores on the analysis set. To more closely ensure that the selected pilot set is a representative sample of controls, one easy step is to specify a list of categorical or binary covariates and sample the pilot set proportionally based on these covariates.</p>
<p>This can be done in one step using <code>auto_stratify</code>, for example:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">a.strat1 &lt;-<span class="st"> </span><span class="kw">auto_stratify</span>(mydata, <span class="st">&quot;treat&quot;</span>,</a>
<a class="sourceLine" id="cb2-2" data-line-number="2">                         <span class="dt">prognosis =</span> outcome <span class="op">~</span><span class="st"> </span>X1 <span class="op">+</span><span class="st"> </span>X2,</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">                         <span class="dt">group_by_covariates =</span> <span class="kw">c</span>(<span class="st">&quot;C1&quot;</span>, <span class="st">&quot;B2&quot;</span>), <span class="dt">size =</span> <span class="dv">500</span>)</a>
<a class="sourceLine" id="cb2-4" data-line-number="4"><span class="co">#&gt; Constructing a pilot set by subsampling 10% of controls.</span></a>
<a class="sourceLine" id="cb2-5" data-line-number="5"><span class="co">#&gt; Subsampling while balancing on:</span></a>
<a class="sourceLine" id="cb2-6" data-line-number="6"><span class="co">#&gt; C1, B2</span></a>
<a class="sourceLine" id="cb2-7" data-line-number="7"><span class="co">#&gt; Fitting prognostic model via logistic regression: outcome ~ X1 + X2</span></a></code></pre></div>
<p>Another method is to use the <code>split_pilot_set</code> function, which allows the user to split the pilot set (and examine the balance) before passing the result to <code>auto_stratify</code> to fit the prognostic score.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">mysplit &lt;-<span class="st"> </span><span class="kw">split_pilot_set</span>(mydata, <span class="st">&quot;treat&quot;</span>, <span class="dt">group_by_covariates =</span> <span class="kw">c</span>(<span class="st">&quot;C1&quot;</span>, <span class="st">&quot;B2&quot;</span>))</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="co">#&gt; Constructing a pilot set by subsampling 10% of controls.</span></a>
<a class="sourceLine" id="cb3-3" data-line-number="3"><span class="co">#&gt; Subsampling while balancing on:</span></a>
<a class="sourceLine" id="cb3-4" data-line-number="4"><span class="co">#&gt; C1, B2</span></a></code></pre></div>
<p>The result, <code>mysplit</code>, is a list containing a <code>pilot_set</code> and an <code>analysis_set</code>, in this case partitioned while balancing on B1 and C2. At this point, we might pass the result to <code>auto_stratify</code> as follows:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1">a.strat2 &lt;-<span class="st"> </span><span class="kw">auto_stratify</span>(mysplit<span class="op">$</span>analysis_set, <span class="st">&quot;treat&quot;</span>,</a>
<a class="sourceLine" id="cb4-2" data-line-number="2">                          <span class="dt">prognosis =</span> outcome <span class="op">~</span><span class="st"> </span>X1 <span class="op">+</span><span class="st"> </span>X2,</a>
<a class="sourceLine" id="cb4-3" data-line-number="3">                          <span class="dt">pilot_sample =</span> mysplit<span class="op">$</span>pilot_set, <span class="dt">size =</span> <span class="dv">500</span>)</a>
<a class="sourceLine" id="cb4-4" data-line-number="4"><span class="co">#&gt; Using user-specified set for prognostic score modeling.</span></a>
<a class="sourceLine" id="cb4-5" data-line-number="5"><span class="co">#&gt; Fitting prognostic model via logistic regression: outcome ~ X1 + X2</span></a></code></pre></div>
<p>In this case, the pilot set splitting method is the same for <code>a.strat1</code> and <code>a.strat2</code>, so each should be qualitatively similar.</p>
</div>
<div id="fitting-the-prognostic-model" class="section level1">
<h1>Fitting the prognostic model</h1>
<p>By default, <code>auto_stratify</code> uses a logistic regression (for binary outcomes) or a linear regression (for continuous outcomes) to fit the prognostic model. <code>auto_stratify</code> is built to accomodate other prognostic score estimation approaches: rather than letting <code>auto_stratify</code> do the model fitting, the user can specify a pre-fit model or a vector of prognostic scores.</p>
<p>A word of caution is advisable: Logistic regression is generally the norm when fitting propensity scores (<span class="citation">Stuart (2010)</span>), and most studies discussing the prognostic score have likewise focused on linear or logistic regression (<span class="citation">Hansen (2008)</span>, <span class="citation">Leacy and Stuart (2014)</span>, <span class="citation">Aikens et al. (2020)</span>), or less commonly the lasso (<span class="citation">Antonelli et al. (2018)</span>). The nuances of modeling and checking the fit of the prognostic score are still understudied. In particular, prognostic models generally are fit on only control observations, meaning that they must necessarily extrapolate to the treatment group. Users should, as always, consider diagnostics for their specific model, for their stratified data set (see “Intro to statamatch”), and for their matched dataset (see, as an introduction <span class="citation">Stuart (2010)</span>). Additionally, in order to maintain the integrity of the pilot set and prevent over-fitting, users interested in trying many modeling or matching schemes are encouraged to define a single pilot/analysis set split (e.g. with <code>split_pilot_set</code>, above) and use the same pilot set throughout their design process.</p>
<p>To an extent, any prognostic score stratification – even on a poor quality model – will increase the speed of matching for large datasets. In addition, if the strata are sufficiently large, the subsequent within-strata matching step may compensate for a poor-quality prognostic model. To one view, the diagnostic check that matters most is the quality of the final matching result, whereas specific prognostic modeling concerns are perhaps secondary. Nonetheless, simulation and theory results suggest that incorporating a prognostic score into a study design (in combination, generally, with a propensity score) can have favorable statistical properties, such as decreasing variance, increasing power in gamma sensitivity analyses, and decreasing dependence on the propensity score (<span class="citation">Stuart (2010)</span>, <span class="citation">Aikens, Greaves, and Baiocchi (2020)</span>, <span class="citation">Antonelli et al. (2018)</span>, <span class="citation">Hansen (2008)</span>). To that end, prognostic models which produce high-quality prognostic score estimates are expected to ultimately produce higher quality designs by improving the prognostic balance of the matched set.</p>
<p>This section contains a few examples to introduce users who may be new to the modeling space. By no means does it begin to cover all of the modeling possibilities, or even all of the nuances of any one model. This is not a tutorial on predictive modeling. Users looking to become more familiar with modeling in R more broadly may be interested in the <a href="https://CRAN.R-project.org/package=caret"><code>caret</code></a> package (<span class="citation">Kuhn (2021)</span>), which implements support for a wide variety of predictive models.</p>
<div id="outcomes-binary-or-continuous" class="section level2">
<h2>Outcomes: Binary or Continuous</h2>
<p>It’s important to select a model which is appropriate to the nature of the outcome of interest. In this tutorial, our sample data has a binary outcome, so we use models appropriate to that outcome. Users with continuous outcomes should use regression models appropriate to continuous outcomes. Other types of outcomes – such as categorical – have not yet been characterized in the prognostic score literature.</p>
</div>
<div id="a-lasso" class="section level2">
<h2>A lasso</h2>
<p>The lasso is a sparsifying linear model – it is a mathematical cousin to linear regression, but it functions well when a substaintial number of the measured covariates are actually uninformative to the outcome. This may be a particularly useful and intuitive approach when there are many measured covariates which may be redundant or uninformative.</p>
<p>The code below uses the <code>glmnet</code> package (<span class="citation">Friedman, Hastie, and Tibshirani (2010)</span>) to fit a cross-validated lasso on the pilot set based on all the measured covariates. In this example, since the outcome is binary, we will run a logistic lasso. This is done by specifying the <code>family = &quot;binomial&quot;</code> argument to <code>cv.glmnet</code> (although other modeling steps are simular for continuous outcomes.)</p>
<p>The code below does some preprocessing to convert the pilot set data to the right format before passing it to <code>cv.glmnet</code>. <code>glmnet</code> expects the input data to be a model matrix rather than a data frame, and it expects outcomes (<code>y_pilot</code>) to be separated from the covariate data (<code>x_pilot</code>).</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="kw">library</span>(glmnet)</a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="co">#&gt; Loading required package: Matrix</span></a>
<a class="sourceLine" id="cb5-3" data-line-number="3"><span class="co">#&gt; Loaded glmnet 4.0</span></a>
<a class="sourceLine" id="cb5-4" data-line-number="4"></a>
<a class="sourceLine" id="cb5-5" data-line-number="5"><span class="co"># fit model on pilot set</span></a>
<a class="sourceLine" id="cb5-6" data-line-number="6">x_pilot &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(outcome <span class="op">~</span><span class="st"> </span>X1 <span class="op">+</span><span class="st"> </span>X2 <span class="op">+</span><span class="st"> </span>B1 <span class="op">+</span><span class="st"> </span>B2 <span class="op">+</span><span class="st"> </span>C1,</a>
<a class="sourceLine" id="cb5-7" data-line-number="7">                        <span class="dt">data =</span> mysplit<span class="op">$</span>pilot_set)</a>
<a class="sourceLine" id="cb5-8" data-line-number="8"></a>
<a class="sourceLine" id="cb5-9" data-line-number="9">y_pilot &lt;-<span class="st"> </span>mysplit<span class="op">$</span>pilot_set <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb5-10" data-line-number="10"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(outcome) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb5-11" data-line-number="11"><span class="st">  </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb5-12" data-line-number="12"></a>
<a class="sourceLine" id="cb5-13" data-line-number="13">cvlasso &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(x_pilot, y_pilot, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a></code></pre></div>
<p>At this point, we can run diagnostics on <code>cvlasso</code>. The <a href="https://glmnet.stanford.edu/articles/glmnet.html">Introduction to glmnet</a> vignette contains an accessible starting point. In this simulated data, we happen to know that the only variable that actually affects the outcome is <code>X1</code>. The sparsifying model often does a great job of picking out <code>X1</code> as the most important variable. We can see this by printing the coefficients:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw">coef</span>(cvlasso)</a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="co">#&gt; 8 x 1 sparse Matrix of class &quot;dgCMatrix&quot;</span></a>
<a class="sourceLine" id="cb6-3" data-line-number="3"><span class="co">#&gt;                       1</span></a>
<a class="sourceLine" id="cb6-4" data-line-number="4"><span class="co">#&gt; (Intercept)  0.02870109</span></a>
<a class="sourceLine" id="cb6-5" data-line-number="5"><span class="co">#&gt; (Intercept)  .         </span></a>
<a class="sourceLine" id="cb6-6" data-line-number="6"><span class="co">#&gt; X1          -0.64374310</span></a>
<a class="sourceLine" id="cb6-7" data-line-number="7"><span class="co">#&gt; X2           .         </span></a>
<a class="sourceLine" id="cb6-8" data-line-number="8"><span class="co">#&gt; B1           .         </span></a>
<a class="sourceLine" id="cb6-9" data-line-number="9"><span class="co">#&gt; B2           .         </span></a>
<a class="sourceLine" id="cb6-10" data-line-number="10"><span class="co">#&gt; C1b          .         </span></a>
<a class="sourceLine" id="cb6-11" data-line-number="11"><span class="co">#&gt; C1c          .</span></a></code></pre></div>
<p>When we are satisfied with our prognostic model, we can estimate the scores on the analysis set with <code>predict</code> and pass the result to <code>auto_stratify</code>.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="co"># estimate scores on analysis set</span></a>
<a class="sourceLine" id="cb7-2" data-line-number="2">x_analysis &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(outcome <span class="op">~</span><span class="st"> </span>X1 <span class="op">+</span><span class="st"> </span>X2 <span class="op">+</span><span class="st"> </span>B1 <span class="op">+</span><span class="st"> </span>B2 <span class="op">+</span><span class="st"> </span>C1,</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">                        <span class="dt">data =</span> mysplit<span class="op">$</span>analysis_set)</a>
<a class="sourceLine" id="cb7-4" data-line-number="4"></a>
<a class="sourceLine" id="cb7-5" data-line-number="5">lasso_scores &lt;-<span class="st"> </span><span class="kw">predict</span>(cvlasso, <span class="dt">newx =</span> x_analysis, <span class="dt">s =</span> <span class="st">&quot;lambda.min&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb7-6" data-line-number="6"></a>
<a class="sourceLine" id="cb7-7" data-line-number="7"><span class="co"># pass the scores to auto_stratify</span></a>
<a class="sourceLine" id="cb7-8" data-line-number="8">a.strat_lasso &lt;-<span class="st"> </span><span class="kw">auto_stratify</span>(<span class="dt">data =</span> mysplit<span class="op">$</span>analysis_set,</a>
<a class="sourceLine" id="cb7-9" data-line-number="9">                             <span class="dt">treat =</span> <span class="st">&quot;treat&quot;</span>,</a>
<a class="sourceLine" id="cb7-10" data-line-number="10">                             <span class="dt">outcome =</span> <span class="st">&quot;outcome&quot;</span>,</a>
<a class="sourceLine" id="cb7-11" data-line-number="11">                             <span class="dt">prognosis =</span> lasso_scores,</a>
<a class="sourceLine" id="cb7-12" data-line-number="12">                             <span class="dt">pilot_sample =</span> mysplit<span class="op">$</span>pilot_set,</a>
<a class="sourceLine" id="cb7-13" data-line-number="13">                             <span class="dt">size =</span> <span class="dv">500</span>)</a></code></pre></div>
</div>
<div id="an-elastic-net" class="section level2">
<h2>An elastic net</h2>
<p>An elastic net is a fairly straightforward extension of the code above – we can use the same form of the pilot set data that we used above. An additional task is to select the <code>alpha</code> “mixing” parameter determining the amount of L2-regularization (1 for lasso, 0 for ridge regression). Here, I set <code>alpha = 0.2</code>. The tutorial for <code>glmnet</code> also contains some advice for selecting the alpha parameter via cross-validation. As above, we specify a logistic elastic net with <code>family = &quot;binomial&quot;</code>, since in this case our outcome is binary.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">cvenet &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(x_pilot, y_pilot, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.2</span>)</a>
<a class="sourceLine" id="cb8-2" data-line-number="2"></a>
<a class="sourceLine" id="cb8-3" data-line-number="3">enet_scores &lt;-<span class="st"> </span><span class="kw">predict</span>(cvenet, <span class="dt">newx =</span> x_analysis, <span class="dt">s =</span> <span class="st">&quot;lambda.min&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb8-4" data-line-number="4"></a>
<a class="sourceLine" id="cb8-5" data-line-number="5"><span class="co"># pass the scores to auto_stratify</span></a>
<a class="sourceLine" id="cb8-6" data-line-number="6">a.strat_enet &lt;-<span class="st"> </span><span class="kw">auto_stratify</span>(<span class="dt">data =</span> mysplit<span class="op">$</span>analysis_set,</a>
<a class="sourceLine" id="cb8-7" data-line-number="7">                             <span class="dt">treat =</span> <span class="st">&quot;treat&quot;</span>,</a>
<a class="sourceLine" id="cb8-8" data-line-number="8">                             <span class="dt">outcome =</span> <span class="st">&quot;outcome&quot;</span>,</a>
<a class="sourceLine" id="cb8-9" data-line-number="9">                             <span class="dt">prognosis =</span> enet_scores,</a>
<a class="sourceLine" id="cb8-10" data-line-number="10">                             <span class="dt">pilot_sample =</span> mysplit<span class="op">$</span>pilot_set,</a>
<a class="sourceLine" id="cb8-11" data-line-number="11">                             <span class="dt">size =</span> <span class="dv">500</span>)</a></code></pre></div>
</div>
<div id="a-random-forest" class="section level2">
<h2>A random forest</h2>
<p>Random forests are a popular option for both classification and regression modeling, particularly because of their strengths in modeling nonlinear relationships in the data. Below is an example which fits a random forest for our binary outcome using <code>randomForest</code>. A note for users with binary outcomes: <code>randomForest</code> will run regression by default if the outcome column is numeric. To circumvent this (e.g. for 0/1 coded data), the outcome can be cast as a factor.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="kw">library</span>(randomForest)</a>
<a class="sourceLine" id="cb9-2" data-line-number="2"><span class="co">#&gt; randomForest 4.6-14</span></a>
<a class="sourceLine" id="cb9-3" data-line-number="3"><span class="co">#&gt; Type rfNews() to see new features/changes/bug fixes.</span></a>
<a class="sourceLine" id="cb9-4" data-line-number="4"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb9-5" data-line-number="5"><span class="co">#&gt; Attaching package: 'randomForest'</span></a>
<a class="sourceLine" id="cb9-6" data-line-number="6"><span class="co">#&gt; The following object is masked from 'package:dplyr':</span></a>
<a class="sourceLine" id="cb9-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb9-8" data-line-number="8"><span class="co">#&gt;     combine</span></a>
<a class="sourceLine" id="cb9-9" data-line-number="9">forest &lt;-<span class="st"> </span><span class="kw">randomForest</span>(<span class="kw">as.factor</span>(outcome) <span class="op">~</span><span class="st"> </span>X1 <span class="op">+</span><span class="st"> </span>X2 <span class="op">+</span><span class="st"> </span>B1 <span class="op">+</span><span class="st"> </span>B2, <span class="dt">data =</span> mysplit<span class="op">$</span>pilot_set)</a></code></pre></div>
<p>Random forests can be somewhat more opaque than linear models in terms of understanding how predictions are made. A good starting point is running <code>importance(forest)</code> to check on which features are weighted heavily in the model.</p>
<p>Below, we extract a “prognostic score” from the random forest. Another note for users with binary outcomes: The <code>predict</code> method for random forest classifiers outputs 0/1 predictions by default. These will be useless for stratification. Instead, we need to specify <code>type = &quot;prob&quot;</code> in the call to predict and extract the probabilities for the “positive” outcome class.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">forest_scores &lt;-<span class="st"> </span><span class="kw">predict</span>(forest,</a>
<a class="sourceLine" id="cb10-2" data-line-number="2">                         <span class="dt">newdata =</span> mysplit<span class="op">$</span>analysis_set,</a>
<a class="sourceLine" id="cb10-3" data-line-number="3">                         <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>)[,<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb10-4" data-line-number="4"></a>
<a class="sourceLine" id="cb10-5" data-line-number="5">a.strat_forest &lt;-<span class="st"> </span><span class="kw">auto_stratify</span>(<span class="dt">data =</span> mysplit<span class="op">$</span>analysis_set,</a>
<a class="sourceLine" id="cb10-6" data-line-number="6">                             <span class="dt">treat =</span> <span class="st">&quot;treat&quot;</span>,</a>
<a class="sourceLine" id="cb10-7" data-line-number="7">                             <span class="dt">outcome =</span> <span class="st">&quot;outcome&quot;</span>,</a>
<a class="sourceLine" id="cb10-8" data-line-number="8">                             <span class="dt">prognosis =</span> forest_scores,</a>
<a class="sourceLine" id="cb10-9" data-line-number="9">                             <span class="dt">pilot_sample =</span> mysplit<span class="op">$</span>pilot_set,</a>
<a class="sourceLine" id="cb10-10" data-line-number="10">                             <span class="dt">size =</span> <span class="dv">500</span>)</a></code></pre></div>
</div>
</div>
<div id="alternative-matching-schemes" class="section level1">
<h1>Alternative matching schemes</h1>
<p>“Intro to Stratamatch” covers only the default functionality of <code>stratamatch</code>, which is a fixed 1:k propensity score match within strata. This tutorial covers some alternative options.</p>
<div id="distance-measure-mahalanobis-distance" class="section level2">
<h2>Distance measure: Mahalanobis Distance</h2>
<p>Users can opt to use Mahalanobis distance rather then propensity score for the within-strata matching step by specifying the “method” to <code>strata_match</code>. We set <code>k = 2</code>, so that precisely 2 control observations are matched to each treated observation.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">mahalmatch &lt;-<span class="st"> </span><span class="kw">strata_match</span>(a.strat2, <span class="dt">model =</span> treat <span class="op">~</span><span class="st"> </span>X1 <span class="op">+</span><span class="st"> </span>X2 <span class="op">+</span><span class="st"> </span>B1 <span class="op">+</span><span class="st"> </span>B2,</a>
<a class="sourceLine" id="cb11-2" data-line-number="2">                           <span class="dt">method =</span> <span class="st">&quot;mahal&quot;</span>, <span class="dt">k =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb11-3" data-line-number="3"><span class="co">#&gt; This function makes essential use of the optmatch package, which has an academic license.</span></a>
<a class="sourceLine" id="cb11-4" data-line-number="4"><span class="co">#&gt; For more information, run optmatch::relaxinfo()</span></a>
<a class="sourceLine" id="cb11-5" data-line-number="5"><span class="co">#&gt; Using Mahalanobis distance: treat ~ X1 + X2 + B1 + B2</span></a>
<a class="sourceLine" id="cb11-6" data-line-number="6"></a>
<a class="sourceLine" id="cb11-7" data-line-number="7"><span class="kw">summary</span>(mahalmatch)</a>
<a class="sourceLine" id="cb11-8" data-line-number="8"><span class="co">#&gt; Structure of matched sets:</span></a>
<a class="sourceLine" id="cb11-9" data-line-number="9"><span class="co">#&gt;  1:2  0:1 </span></a>
<a class="sourceLine" id="cb11-10" data-line-number="10"><span class="co">#&gt; 1146 1176 </span></a>
<a class="sourceLine" id="cb11-11" data-line-number="11"><span class="co">#&gt; Effective Sample Size:  1528 </span></a>
<a class="sourceLine" id="cb11-12" data-line-number="12"><span class="co">#&gt; (equivalent number of matched pairs).</span></a></code></pre></div>
</div>
<div id="matching-procedure-full-matching" class="section level2">
<h2>Matching procedure: Full Matching</h2>
<p>Full matching may be a particularly useful approach when the ratio of treated to control individuals varies within strata, but the researcher still would prefer to use as much of the data as possible. To do full matching, set <code>k = &quot;full&quot;</code>. This can be used in combination with mahalanobis distance matching, as shown below:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1">fullmahalmatch &lt;-<span class="st"> </span><span class="kw">strata_match</span>(a.strat2, <span class="dt">model =</span> treat <span class="op">~</span><span class="st"> </span>X1 <span class="op">+</span><span class="st"> </span>X2 <span class="op">+</span><span class="st"> </span>B1 <span class="op">+</span><span class="st"> </span>B2,</a>
<a class="sourceLine" id="cb12-2" data-line-number="2">                           <span class="dt">method =</span> <span class="st">&quot;mahal&quot;</span>, <span class="dt">k =</span> <span class="st">&quot;full&quot;</span>)</a>
<a class="sourceLine" id="cb12-3" data-line-number="3"><span class="co">#&gt; This function makes essential use of the optmatch package, which has an academic license.</span></a>
<a class="sourceLine" id="cb12-4" data-line-number="4"><span class="co">#&gt; For more information, run optmatch::relaxinfo()</span></a>
<a class="sourceLine" id="cb12-5" data-line-number="5"><span class="co">#&gt; Using Mahalanobis distance: treat ~ X1 + X2 + B1 + B2</span></a>
<a class="sourceLine" id="cb12-6" data-line-number="6"></a>
<a class="sourceLine" id="cb12-7" data-line-number="7"><span class="kw">summary</span>(fullmahalmatch)</a>
<a class="sourceLine" id="cb12-8" data-line-number="8"><span class="co">#&gt; Structure of matched sets:</span></a>
<a class="sourceLine" id="cb12-9" data-line-number="9"><span class="co">#&gt; 5+:1  4:1  3:1  2:1  1:1  1:2  1:3  1:4 1:5+ </span></a>
<a class="sourceLine" id="cb12-10" data-line-number="10"><span class="co">#&gt;    8    6   14   43  448  135   87   69  204 </span></a>
<a class="sourceLine" id="cb12-11" data-line-number="11"><span class="co">#&gt; Effective Sample Size:  1331.7 </span></a>
<a class="sourceLine" id="cb12-12" data-line-number="12"><span class="co">#&gt; (equivalent number of matched pairs).</span></a></code></pre></div>
</div>
<div id="matching-with-other-software" class="section level2">
<h2>Matching with other software</h2>
<p><code>stratamatch</code> doesn’t natively support all possible matching schemes. Luckily, it can be fairly straightforward to stratify a data set with <code>auto_stratify</code> and match the results with other software. As an example, the code below uses the <code>optmatch</code> package (<span class="citation">Hansen and Klopfer (2006)</span>) to match within-strata using Mahalanobis distance with a propensity score caliper.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="kw">library</span>(optmatch)</a>
<a class="sourceLine" id="cb13-2" data-line-number="2"><span class="co">#&gt; Loading required package: survival</span></a>
<a class="sourceLine" id="cb13-3" data-line-number="3"><span class="co">#&gt; The optmatch package has an academic license. Enter relaxinfo() for more information.</span></a>
<a class="sourceLine" id="cb13-4" data-line-number="4"></a>
<a class="sourceLine" id="cb13-5" data-line-number="5"><span class="co"># mahalanobis distance matrix for within-strata matching</span></a>
<a class="sourceLine" id="cb13-6" data-line-number="6">mahaldist &lt;-<span class="st"> </span><span class="kw">match_on</span>(treat <span class="op">~</span><span class="st"> </span>X1 <span class="op">+</span><span class="st"> </span>X2 <span class="op">+</span><span class="st"> </span>B1 <span class="op">+</span><span class="st"> </span>B2, </a>
<a class="sourceLine" id="cb13-7" data-line-number="7">                      <span class="dt">within =</span> <span class="kw">exactMatch</span>(treat <span class="op">~</span><span class="st"> </span>stratum,</a>
<a class="sourceLine" id="cb13-8" data-line-number="8">                                          <span class="dt">data =</span> a.strat2<span class="op">$</span>analysis_set),</a>
<a class="sourceLine" id="cb13-9" data-line-number="9">                      <span class="dt">data =</span> a.strat2<span class="op">$</span>analysis_set)</a>
<a class="sourceLine" id="cb13-10" data-line-number="10"></a>
<a class="sourceLine" id="cb13-11" data-line-number="11"><span class="co"># add propensity score caliper</span></a>
<a class="sourceLine" id="cb13-12" data-line-number="12">propdist &lt;-<span class="st"> </span><span class="kw">match_on</span>(<span class="kw">glm</span>(treat <span class="op">~</span><span class="st"> </span>X1 <span class="op">+</span><span class="st"> </span>X2 <span class="op">+</span><span class="st"> </span>B1 <span class="op">+</span><span class="st"> </span>B2,</a>
<a class="sourceLine" id="cb13-13" data-line-number="13">                         <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,</a>
<a class="sourceLine" id="cb13-14" data-line-number="14">                         <span class="dt">data =</span> a.strat2<span class="op">$</span>analysis_set))</a>
<a class="sourceLine" id="cb13-15" data-line-number="15"></a>
<a class="sourceLine" id="cb13-16" data-line-number="16">mahalcaliper &lt;-<span class="st"> </span>mahaldist <span class="op">+</span><span class="st"> </span><span class="kw">caliper</span>(propdist, <span class="dt">width =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb13-17" data-line-number="17"></a>
<a class="sourceLine" id="cb13-18" data-line-number="18">mahalcaliper_match &lt;-<span class="st"> </span><span class="kw">pairmatch</span>(mahalcaliper, <span class="dt">data =</span> a.strat2<span class="op">$</span>analysis_set)</a>
<a class="sourceLine" id="cb13-19" data-line-number="19"><span class="co">#&gt; Warning in fullmatch.BlockedInfinitySparseMatrix(x = x, min.controls = controls, : At least one subproblem matching failed.</span></a>
<a class="sourceLine" id="cb13-20" data-line-number="20"><span class="co">#&gt;  (Restrictions impossible to meet?)</span></a>
<a class="sourceLine" id="cb13-21" data-line-number="21"><span class="co">#&gt;  Enter ?matchfailed for more info.</span></a>
<a class="sourceLine" id="cb13-22" data-line-number="22"></a>
<a class="sourceLine" id="cb13-23" data-line-number="23"><span class="kw">summary</span>(mahalcaliper_match)</a>
<a class="sourceLine" id="cb13-24" data-line-number="24"><span class="co">#&gt; Matches made in 8 of 10 subgroups, accounting for 3691 of 4614 total observations.</span></a>
<a class="sourceLine" id="cb13-25" data-line-number="25"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb13-26" data-line-number="26"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb13-27" data-line-number="27"><span class="co">#&gt; Structure of matched sets:</span></a>
<a class="sourceLine" id="cb13-28" data-line-number="28"><span class="co">#&gt;  1:0  1:1  0:1 </span></a>
<a class="sourceLine" id="cb13-29" data-line-number="29"><span class="co">#&gt;  192  954 2514 </span></a>
<a class="sourceLine" id="cb13-30" data-line-number="30"><span class="co">#&gt; Effective Sample Size:  954 </span></a>
<a class="sourceLine" id="cb13-31" data-line-number="31"><span class="co">#&gt; (equivalent number of matched pairs).</span></a></code></pre></div>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-aikens2020pilot">
<p>Aikens, Rachael C, Dylan Greaves, and Michael Baiocchi. 2020. “A Pilot Design for Observational Studies: Using Abundant Data Thoughtfully.” <em>Statistics in Medicine</em>. Wiley Online Library.</p>
</div>
<div id="ref-aikens2020stratified">
<p>Aikens, Rachael C, Joseph Rigdon, Justin Lee, Michael Baiocchi, Andrew B Goldstone, Peter Chiu, Y Joseph Woo, and Jonathan H Chen. 2020. “Stratified Pilot Matching in R: The Stratamatch Package.” <em>Statistics arXiv</em>, January. <a href="https://arxiv.org/abs/2001.02775">https://arxiv.org/abs/2001.02775</a>.</p>
</div>
<div id="ref-antonelli2018doubly">
<p>Antonelli, Joseph, Matthew Cefalu, Nathan Palmer, and Denis Agniel. 2018. “Doubly Robust Matching Estimators for High Dimensional Confounding Adjustment.” <em>Biometrics</em> 74 (4). Wiley Online Library: 1171–9.</p>
</div>
<div id="ref-friedman2010regularization">
<p>Friedman, Jerome, Trevor Hastie, and Rob Tibshirani. 2010. “Regularization Paths for Generalized Linear Models via Coordinate Descent.” <em>Journal of Statistical Software</em> 33 (1). NIH Public Access: 1.</p>
</div>
<div id="ref-hansen2008prognostic">
<p>Hansen, Ben B. 2008. “The Prognostic Analogue of the Propensity Score.” <em>Biometrika</em> 95 (2). Oxford University Press: 481–88.</p>
</div>
<div id="ref-hansen2006optmatch">
<p>Hansen, Ben B., and Stephanie Olsen Klopfer. 2006. “Optimal Full Matching and Related Designs via Network Flows.” <em>Journal of Computational and Graphical Statistics</em> 15 (3): 609–27.</p>
</div>
<div id="ref-caret2021">
<p>Kuhn, Max. 2021. <em>Caret: Classification and Regression Training</em>. <a href="https://CRAN.R-project.org/package=caret">https://CRAN.R-project.org/package=caret</a>.</p>
</div>
<div id="ref-leacy2014joint">
<p>Leacy, Finbarr P, and Elizabeth A Stuart. 2014. “On the Joint Use of Propensity and Prognostic Scores in Estimation of the Average Treatment Effect on the Treated: A Simulation Study.” <em>Statistics in Medicine</em> 33 (20). Wiley Online Library: 3488–3508.</p>
</div>
<div id="ref-stuart2010matching">
<p>Stuart, Elizabeth A. 2010. “Matching Methods for Causal Inference: A Review and a Look Forward.” <em>Statistical Science: A Review Journal of the Institute of Mathematical Statistics</em> 25 (1). NIH Public Access: 1.</p>
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
